{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dc1ba39-0e4f-4410-bf47-b7a1a6f3b1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25a0bfc-cb75-45fa-8a85-a89d9c2a6d7a",
   "metadata": {},
   "source": [
    "### QuestionCounter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3090a98e-f2e9-41e7-8a13-58f37d55993b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionCounter(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    A custom Pipeline transformer class used to generate counts of a set of questions by a single given demogrpahic.\n",
    "\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    demographics : list of str\n",
    "        a list of demographic column names to break down the counts by\n",
    "    question_columns : list of str or pandas.Index of str, default=[]\n",
    "        a list of column names representing the questions we want counts of\n",
    "    multiselect_stem_ids : list of str, default=[]\n",
    "        a list of question stem IDs of multi-select questions\n",
    "    stem_id_dict : dict\n",
    "        a dictionary with question stem IDs as keys and their corresponding list of question item IDs as values\n",
    "    use_feature_union : bool, default=False\n",
    "        whether or not the result is input to FeatureUnion. Stores column names into 1st row of dataframe if True.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fit(self, X, y=None)\n",
    "    transform(self, X, y=None)\n",
    "        Returns a dataframe with counts for each demographic value, for each question item\n",
    "    get_question_stem_ids(self)\n",
    "        Returns a list of question stem IDs\n",
    "    \"\"\"\n",
    "    def __init__(self, demographics, question_columns=[], multiselect_stem_ids=[], use_feature_union=False):\n",
    "        self.demographics = demographics\n",
    "        self.question_columns = pd.Index(question_columns)\n",
    "        self.multiselect_stem_ids = multiselect_stem_ids\n",
    "        self.stem_id_dict = dict()\n",
    "        self.use_feature_union = use_feature_union\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        def build_question_stem_ids(survey_df, multiselect_stems):\n",
    "            \"\"\"Populates question_columns; Creates the stem_id_dict dictionary with keys as question stem ids, values as corresponding question item ids\n",
    "            \"\"\"\n",
    "            if len(self.question_columns) == 0:\n",
    "                # excludes open-text columns\n",
    "                self.question_columns = survey_df.columns[survey_df.columns.str.contains('^(?!.*_TEXT$)[A-Z\\.0-9_]+$', regex=True)].str.strip()\n",
    "            stem_id_dict = {}\n",
    "            for i, item_id in enumerate(self.question_columns):\n",
    "                stem_id = pd.Series(item_id).str.split('_\\d+(?!\\.)$', regex=True).values[0][0]\n",
    "                if stem_id in multiselect_stems and stem_id not in stem_id_dict.keys():\n",
    "                    question_item_ids = self.question_columns[self.question_columns.str.contains(stem_id)].tolist()\n",
    "                    stem_id_dict[stem_id] = question_item_ids\n",
    "                elif stem_id not in stem_id_dict.keys():\n",
    "                    # single-select question item = question stem\n",
    "                    stem_id_dict[item_id] = [item_id]     \n",
    "            return stem_id_dict\n",
    "            \n",
    "        self.stem_id_dict = build_question_stem_ids(X, self.multiselect_stem_ids)\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        def add_id_columns(count_df, item_id, stem_id=None):\n",
    "            \"\"\"Adds question item and question stem columns to dataframe\n",
    "            \"\"\"\n",
    "            if stem_id is None:\n",
    "                stem_id = item_id\n",
    "            count_df.insert(0, 'Question Item Id', item_id)\n",
    "            count_df.insert(0, 'Question Stem Id', stem_id)\n",
    "            return count_df\n",
    "            \n",
    "        def count_responses(survey_df, demographics, stem_id):\n",
    "            \"\"\"Counts number of responses for a given question, broken down by given demographic(s)\n",
    "            \"\"\"\n",
    "            # only for non-select-all-that-apply questions\n",
    "            item_id = stem_id\n",
    "            count_df = survey_df.groupby(demographics+[item_id]).size().to_frame('Count')\n",
    "            # include rows where there are 0 responses; for uniformity purposes w/ demog total count\n",
    "            count_df = count_df.unstack(fill_value=0).stack().reset_index()\n",
    "            count_df = count_df.rename(columns={item_id: 'Question Response'})\n",
    "            if count_df['Question Response'].dtype == 'object':\n",
    "                count_df['Question Response'] = count_df['Question Response'].str.strip()\n",
    "            return count_df\n",
    "        \n",
    "        def count_all_questions(survey_df, demographics, question_stem_ids):\n",
    "            \"\"\"Creates a dataframe with number of responses, by demographics, for each single-select question (stem)\n",
    "            \"\"\"\n",
    "            question_counts_df = pd.DataFrame()\n",
    "            has_duplicate_demographics = pd.Series(demographics).duplicated().sum() > 0\n",
    "            if has_duplicate_demographics:\n",
    "                # happens when the demographic category is the same as the secondary/additional demographic breakdown\n",
    "                demographics = pd.Series(demographics)[~pd.Series(demographics).duplicated()].tolist()\n",
    "            for stem_id in question_stem_ids:\n",
    "                count_df = count_responses(survey_df, demographics, stem_id)\n",
    "                #total_df = count_total(survey_df)\n",
    "                ###########\n",
    "                # TO-DO: make it compatible to barriers to discovery\n",
    "                demographic_category = demographics[0]\n",
    "                count_df.insert(0, 'Demographic Category', demographic_category)\n",
    "                count_df = count_df.rename(columns={demographic_category: 'Demographic Value'})\n",
    "                if has_duplicate_demographics:\n",
    "                    count_df.insert(2, demographic_category, count_df['Demographic Value'].copy())\n",
    "                ###########\n",
    "                count_df = add_id_columns(count_df, item_id=stem_id, stem_id=stem_id)\n",
    "                question_counts_df = pd.concat([question_counts_df, count_df], ignore_index=True)\n",
    "            return question_counts_df\n",
    "        \n",
    "        question_stem_ids = self.get_question_stem_ids()\n",
    "        single_select_stem_ids = [stem_id for stem_id in question_stem_ids if len(self.stem_id_dict[stem_id])==1]\n",
    "        counts_data_source = count_all_questions(X, self.demographics, single_select_stem_ids)\n",
    "        if self.use_feature_union: # store columnn names in 1st row of dataframe\n",
    "            counts_data_source = pd.DataFrame([counts_data_source.columns] + counts_data_source.values.tolist())\n",
    "        return counts_data_source\n",
    "\n",
    "    def get_question_stem_ids(self):\n",
    "        \"\"\"Returns a list of question stem IDs\n",
    "        \"\"\"\n",
    "        return self.stem_id_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f93888e-ecb4-4a84-80c6-3efc726fe0b8",
   "metadata": {},
   "source": [
    "### IdDescColumnsAdder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b145c02b-b269-49e3-955d-d71f7d0c0c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdDescColumnsAdder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    A custom Pipeline transformer class used to add to an existing dataframe question stem and item descriptions (ie. \"Question Stem\" and \"Question Item\" columns).\n",
    "\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    question_descriptions : DataFrame\n",
    "        a single-row dataframe where column names are question (item) IDs and cell values are the question text\n",
    "        NOTE: Columns should match columns of pulse survey data file.\n",
    "              For demographic category columns, cell values should reflect the Demographic Category names used in final data source.\n",
    "              Other columns can just match column names.\n",
    "    use_feature_union : bool, default=False\n",
    "        whether or not the result is input to FeatureUnion. Stores column names into 1st row of dataframe if True.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fit(self, X, y=None)\n",
    "    transform(self, X, y=None)\n",
    "        Returns the dataframe that was passed into it (the \"X\" variable), with 2 columns (\"Question Stem\" & \"Question Item\") added to it\n",
    "    \"\"\"\n",
    "    def __init__(self, question_descriptions, use_feature_union=True):\n",
    "        self.question_descriptions = pd.DataFrame(question_descriptions)\n",
    "        self.use_feature_union = use_feature_union\n",
    "        \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y = None):\n",
    "        for item_id in X['Question Item Id'].unique():\n",
    "            stem_id = X.loc[X['Question Item Id']==item_id, 'Question Stem Id'].unique()[0]\n",
    "            regex_split_item_stem_str = '\\?(?:\\s?(?:Select all that apply\\. - Selected Choice -|(?:Check|Select) all that apply\\. -)\\s?|\\s?-\\s?)'\n",
    "            stem, item = '',''\n",
    "            try:\n",
    "                stem, item = self.question_descriptions[item_id].str.split(regex_split_item_stem_str, regex=True)[0]\n",
    "            except ValueError as error:\n",
    "                if str(error) == \"not enough values to unpack (expected 2, got 1)\": # question only has a stem\n",
    "                    stem = self.question_descriptions[item_id].str.split(regex_split_item_stem_str, regex=True)[0][0]\n",
    "            except KeyError as no_ques_desc_error:\n",
    "                stem = item_id\n",
    "            \n",
    "            X.loc[X['Question Item Id']==item_id, 'Question Item'] = item.strip()\n",
    "            X.loc[X['Question Stem Id']==stem_id, 'Question Stem'] = stem.strip()\n",
    "        if self.use_feature_union:\n",
    "            X = pd.DataFrame([X.columns] + X.values.tolist())\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408acca9-2ea7-4e85-b8f8-794ec584c507",
   "metadata": {},
   "source": [
    "### TotalsCounter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb6132e1-d52d-44e8-8735-374df17144e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TotalsCounter(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    A custom Pipeline transformer class used to generate counts of a set of questions by a demogrpahic.\n",
    "\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    demographics : list of str\n",
    "        a list of demographic column names to break down the counts by\n",
    "    question_columns : list of str or pandas.Index of str, default=[]\n",
    "        a list of column names representing the questions we want counts of\n",
    "    multiselect_stem_ids : list of str, default=[]\n",
    "        a list of question stem IDs of multi-select questions\n",
    "    stem_id_dict : dict\n",
    "        a dictionary with question stem IDs as keys and their corresponding list of question item IDs as values\n",
    "    use_feature_union : bool, default=False\n",
    "        whether or not the result is input to FeatureUnion. Stores column names into 1st row of dataframe if True.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fit(self, X, y=None)\n",
    "    transform(self, X, y=None)\n",
    "        Returns a dataframe with columns showing each question item total count, question stem total count, each demographic value's total \n",
    "        count (per question item), and demographic value total by a demographic breakdown (eg. demographic value total, by undergrad/grad)\n",
    "        NOTE: Row ordering should be the same as dataframes generated by QuestionCounter\n",
    "    get_question_stem_ids(self)\n",
    "        Returns a list of question stem IDs\n",
    "    \"\"\"\n",
    "    def __init__(self, demographics, question_columns=[], multiselect_stem_ids=[], use_feature_union=True):\n",
    "        self.demographics = demographics\n",
    "        self.question_columns = pd.Index(question_columns)\n",
    "        self.multiselect_stem_ids = multiselect_stem_ids\n",
    "        self.stem_id_dict = dict()\n",
    "        self.use_feature_union = use_feature_union\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        def build_question_stem_ids(survey_df, multiselect_stems):\n",
    "            \"\"\"Populates question_columns; Creates the stem_id_dict dictionary with keys as question stem ids, values as corresponding question item ids\n",
    "            \"\"\"\n",
    "            if len(self.question_columns) == 0:\n",
    "                # excludes open-text columns\n",
    "                self.question_columns = survey_df.columns[survey_df.columns.str.contains('^(?!.*_TEXT$)[A-Z\\.0-9_]+$', regex=True)].str.strip()\n",
    "            stem_id_dict = {}\n",
    "            for i, item_id in enumerate(self.question_columns):\n",
    "                stem_id = pd.Series(item_id).str.split('_\\d+(?!\\.)$', regex=True).values[0][0]\n",
    "                if stem_id in multiselect_stems and stem_id not in stem_id_dict.keys():\n",
    "                    question_item_ids = self.question_columns[self.question_columns.str.contains(stem_id)].tolist()\n",
    "                    stem_id_dict[stem_id] = question_item_ids\n",
    "                elif stem_id not in stem_id_dict.keys():\n",
    "                    # single-select question item = question stem\n",
    "                    stem_id_dict[item_id] = [item_id]     \n",
    "            return stem_id_dict\n",
    "\n",
    "        self.stem_id_dict = build_question_stem_ids(X, self.multiselect_stem_ids)\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y = None):\n",
    "        def count_total(survey_df, demographics, stem_id, has_duplicate_demographics=False):\n",
    "            \"\"\"Counts total number of responses for a given question item/stem and given demographic groups\n",
    "            \"\"\"\n",
    "            # calculate Question Item Total, Question Stem Total, Demographic Totals\n",
    "            item_id = self.stem_id_dict[stem_id][0]\n",
    "            if has_duplicate_demographics:\n",
    "                total_df = survey_df.groupby(demographics[1:]+[item_id]).size().to_frame('Count')\n",
    "            else:\n",
    "                total_df = survey_df.groupby(demographics+[item_id]).size().to_frame('Count')\n",
    "            # include rows where there are 0 responses; for uniformity purposes w/ demog total count\n",
    "            total_df = total_df.unstack(fill_value=0).stack().reset_index()\n",
    "            demographic_category = demographics[0]\n",
    "            if total_df.shape[0] > 0:\n",
    "                if len(demographics) == 1: # only 1 demographic breakdown\n",
    "                    total_df['Demographic Value Total'] = total_df.groupby(demographic_category)['Count'].transform('sum')\n",
    "                elif len(demographics) > 1: # 1 or more additional breakdowns (eg. entry status, by undergrad/grad OR entry status, by undegrad/grad by year)\n",
    "                    total_df['Demographic Value Total'] = total_df.groupby(demographic_category)['Count'].transform('sum')\n",
    "                    for demog in demographics[1:]:\n",
    "                        if demographic_category == demog:\n",
    "                            demographic_groups = [demographic_category]\n",
    "                        else:\n",
    "                            demographic_groups = [demographic_category, demog]\n",
    "                        total_df['Demographic Value Total, by {}'.format(demog)] = total_df.groupby(demographic_groups)['Count'].transform('sum')\n",
    "                    if len(demographics) > 2:\n",
    "                        demographics = pd.Series(demographics)[~pd.Series(demographics).duplicated()].tolist()\n",
    "                        total_df['Demographic Value Total, by {}'.format(' & '.join(demographics[1:]))] = total_df.groupby(demographics)['Count'].transform('sum')\n",
    "            \n",
    "                total_df = total_df.rename(columns={item_id: 'Question Response'})\n",
    "                total_df['Question Stem Total'] = survey_df[stem_id].dropna().shape[0]\n",
    "                total_df['Question Item Total'] = survey_df[item_id].dropna().shape[0] # only for non-select-all-that-apply questions\n",
    "                total_cols = total_df.columns[total_df.columns.str.contains('Total')]\n",
    "                return total_df[total_cols] # only return total columns\n",
    "            else:\n",
    "                return pd.DataFrame()\n",
    "        \n",
    "        def count_all_questions(survey_df, demographics, question_stem_ids):\n",
    "            \"\"\"Creates a dataframe with total number of responses, by demographics, for each single-select question (stem)\n",
    "            \"\"\"\n",
    "            total_counts_df = pd.DataFrame()\n",
    "            has_duplicate_demographics = pd.Series(demographics).duplicated().sum() > 0\n",
    "            for stem_id in question_stem_ids:\n",
    "                total_df = count_total(survey_df, demographics, stem_id, has_duplicate_demographics)\n",
    "                total_counts_df = pd.concat([total_counts_df, total_df], ignore_index=True)\n",
    "            return total_counts_df\n",
    "\n",
    "        question_stem_ids = self.get_question_stem_ids()\n",
    "        single_select_stem_ids = [stem_id for stem_id in question_stem_ids if len(self.stem_id_dict[stem_id])==1]\n",
    "        total_counts = count_all_questions(X, self.demographics, single_select_stem_ids)\n",
    "        if self.use_feature_union: # store columnn names in 1st row of dataframe\n",
    "            total_counts = pd.DataFrame([total_counts.columns] + total_counts.values.tolist())\n",
    "        return total_counts\n",
    "\n",
    "    def get_question_stem_ids(self):\n",
    "        \"\"\"Returns a list of question stem IDs\n",
    "        \"\"\"\n",
    "        return self.stem_id_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63d579b-ea90-4a04-9fa9-4cad12da42ee",
   "metadata": {},
   "source": [
    "### DoubleCountDataframeTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bacd169c-d0f9-48aa-bfb1-83dc140d9473",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleCountDataframeTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    A custom Pipeline transformer class used to generate duplicate rows for demographic variables that require double counting.\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    demographic : str\n",
    "        a string indicating the demographic category to be double counted. Should match the column name in the dataframe passed in (the \"X\" variable)\n",
    "        NOTE: This class will simply return the original dataframe if the demographic specified cannot be double counted.\n",
    "              A double counting demographic will be a column with lists of to-be-double-counted values in each row.\n",
    "        \n",
    "    Methods\n",
    "    -------\n",
    "    fit(self, X, y=None)\n",
    "    transform(self, X, y=None)\n",
    "        Returns the dataframe that was passed into it (the \"X\" variable), double counted (ie. with duplicate responses that only has different values for the demographic)\n",
    "    \"\"\"\n",
    "    def __init__(self, demographic):\n",
    "        self.demographic = demographic\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"Creates a dataframe that double counts (\"explodes\") rows by the given demographic column.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : dataframe with a column name matching self.demographic\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Pandas DataFrame\n",
    "        \"\"\"\n",
    "        # won't change anything if the given demographic has no list of values to double count\n",
    "        double_count_df = X.explode(self.demographic, ignore_index=True)\n",
    "        return double_count_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd2b794-dcfc-4597-9fbc-6b1fbb3f842a",
   "metadata": {},
   "source": [
    "### ArrToDataframeTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e00d9ecd-004b-4be7-a079-1566c3b489fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArrToDataframeTransformer(TransformerMixin):\n",
    "    \"\"\"\n",
    "    A custom Pipeline transformer class used to convert 2D numpy arrays to a Pandas DataFrame.\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    None\n",
    "            \n",
    "    Methods\n",
    "    -------\n",
    "    fit(self, X, y=None)\n",
    "    transform(self, X, y=None)\n",
    "        Returns a dataframe with the first row of the input arrays as column names\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"Creates a dataframe with the first row of the input array as column names \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 2D numpy array\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Pandas DataFrame\n",
    "        \"\"\"\n",
    "        df = pd.DataFrame(X, columns=X[0,:])\n",
    "        return df.drop(0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e3ea62-e584-4e1e-9121-35b9dd3da08b",
   "metadata": {},
   "source": [
    "### DataframeTransposer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3466a10-1565-43a6-bb00-536b412f54c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataframeTransposer(TransformerMixin):\n",
    "    \"\"\"\n",
    "    A custom Pipeline transformer class used to transpose DataFrames or 2D numpy arrays\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    None\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    fit(self, X, y=None)\n",
    "    transform(self, X, y=None)\n",
    "        Returns the original dataframe (the \"X\" variable), transposed\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"Transposes a dataframe or a 2D array\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 2D numpy array or pandas dataframe\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        2D numpy array or pandas dataframe\n",
    "        \"\"\"\n",
    "        return X.T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
